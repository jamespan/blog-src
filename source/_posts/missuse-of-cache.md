title: 一种错误的缓存使用方式
tags:
  - MySQL
  - Cache
categories:
  - Work
cc: true
hljs: true
comments: true
date: 2015-01-24 11:09:56
---

# 背景

从上周开始我就一直在做数据清洗的工作，这次算是体会到了什么叫做“抛开数据量谈实现就是耍流氓”。

我设计方案和调试代码连接的都是日常环境的数据库，里面的单表数据量在百级，无论我怎么实现都是瞬间洗完。到了性能测试的时候用的就是性能库，双 11 之前@W君做性能测试的时候，往里面写入了 2000W 的数据，足够我战个痛快。

上一篇文章《{% post_link trick-of-paging-query %}》中我解决了分页查询遇到的性能问题，整个数据清洗代码的性能虽有提升，但是十分有限。这说明了其实分页查询不是性能最热点，路漫漫其修远兮。

<!-- more -->

# 发现

一开始从性能日志根本看不出问题，后来仔细翻看了一下输出性能日志的代码，发现我只在更新数据库的时候写了日志，查询数据库的代码，没有输出日志。加上日志后重新执行清洗，问题粗线了！

从日志来看，代码对数据库的读写比例是几百比一，也就是做了百来两百次查询之后，才会有一次更新产生。为什么会这样呢？

# 根源

基于对软硬件的不信任，我对洗数据的代码做了功能增强：断点续传功能，记录当前执行进度，以便程序中断后继续执行；洗过判定功能，更新数据库之前判断待更新记录在逻辑上是否已经被清洗过，避免重复清洗造成的脏数据风险。

断点续传是基于当前分页的 minId 实现的，一旦从中断处继续执行，必然会重新读取该页数据进行清洗，如果没有洗过判定，就可能对逻辑上已经清洗过的记录重复清洗，影响数据的准确性。

最初的设计是程序使用一个本地缓存记录已经被清洗过的记录的关键信息，当代码扫描到一行记录时，如果这行记录的关键信息在本地缓存中，则该记录逻辑上已经清洗过，直接抛弃接着处理下一行记录。

在我的想象中，这个方案在内存足够大，应用不重启的时候有着完美的性能，但是现实世界总是残酷的，内存十分有限，应用可能崩溃。

Guava 是 Java 世界中一个伟大的轮子，也是我最喜欢的类库。我直接使用的 LocalManualCache 作为本地缓存，设置了缓存中记录的数量上限以免发生 OOM。有了容量上限之后，缓存中查不到当前记录的关键信息，就有两种可能，要么这条记录逻辑上没被清洗过，要么逻辑上被清洗了，但是相关信息被缓存的 LRU 算法替换掉了。于是缓存不命中的时候，程序得发起一次数据库查询，看看这行记录逻辑上到底有没有被处理过，并将相关信息写入缓存。

由于 LocalManualCache 不支持批量查询，洗过判定是通过使用循环去遍历当前分页的数据，然后一次一次访问缓存，一旦缓存不命中就查询数据库的方式实现的。

看起来这里的循环查询数据库确实成了性能瓶颈，得想办法不要循环查询才好。

# 歧路

首先想到的是一个朴素的方法，既然是缓存容量有上限造成了缓存不命中的二义性，那我就用一个容量”无限“的缓存好了。正好现在的应用里面有用到这样的缓存系统，类似于 Memcached，我直接复用就好了。

吭哧吭哧把本地缓存替换成了缓存系统，发现系统性能变化不大。一个原因是查询缓存系统有网络开销，就算查询一次耗时 1ms，循环查 200 次的话耗时至少 200ms。考虑到线上数据的形态，缓存能够帮我拦截的数据库查询请求不过比 1% 多那么零点几，大部分的情况还是击穿了缓存去数据库逛了一圈发现记录没被清洗过。

我的心好痛，缓存居然只能帮我挡下 1% 的数据库查询，我开始思考缓存方案的合理性。

一般场景下，缓存是这样使用的。缓存中取到的结果直接参与后续的运算。而且每次“事务”中只需要查询 1 次缓存，至多查询 1 次数据库。随着时间的推移，缓存中的数据愈发完整，对数据库的查询越来越少。

```python
cached = cache.get(key)
if cached is not None:
    return cached
db_result = db.query(key)
cache.put(key, db_result)
return db_result
```

然而在数据清洗的场景下，缓存中取到的结果不参与后续的运算，缓存中取不到结果的，需要去数据库确认缓存的正确性，然后才能参与后续运算。这样一来每次“事务”中需要查询 200 次缓存，至多查询 200 次数据库，平均至少查询 198 次数据库。如此看来，我使用缓存的方式不仅没能帮我提升性能，反而损害了性能。

# 涅槃

我决定不使用缓存了。

洗过判定还是要做的。脱离了缓存的限制，我可以直接使用组合条件在一次查询中得到当前分页中那些被逻辑清洗过的记录，然后将这些记录从待清洗列表中排除。

原先的代码在各种改动之后已经让我不忍直视了，我只好完全重写。事实证明，在一份开始腐烂的代码上做修改，远远没有另起炉灶来的方便。

代码重写花了我大概半小时，日志、开关一应俱全。对数据库的查询从每页 200 次下降到了每页 1 次，性能上也达到了可以接受的程度。

# 扩展

有没有这样一种可能，先用缓存把那些在缓存中的记录过滤，再用组合条件去做一次性查询？

这种方式在功能上是没问题的，我之所以没有采用，是出于工程和性能方面的考虑。

首先，用组合条件查询当前分页中被逻辑清洗过的记录，一次至多查询出 200 条，而且我给的组合条件能够让数据库使用索引完成查询，性能上可以接受。

其次，引入缓存会在一定程度上增加代码的复杂度，效果只有 1%，可以忽略不计，性价比极低。

最后，使用本地缓存需要限制容量上限，造成缓存不可信；使用缓存系统有额外的网络开销，最终带来的耗时远高于直接查询数据库。

# 总结

没有银弹，缓存在大多数场景下能帮助提升性能，但仅仅是大多数场景。

误用工具比不用工具要糟糕得多。
